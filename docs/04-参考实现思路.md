# LexAI 精细化开发路线图 V2.0

## 前置准备：技术评估与团队组建（1周）

### 技术栈可行性验证

在正式开发前，必须验证核心技术难点：

#### 1. PyO3/Maturin 集成验证

```bash
# 创建测试项目
cargo new --lib rust_test
cd rust_test

# Cargo.toml
[lib]
name = "rust_test"
crate-type = ["cdylib"]

[dependencies]
pyo3 = "0.21.2"
extractous = "0.1.0"  # 验证文档解析库

# 编写简单测试
# src/lib.rs
use pyo3::prelude::*;

#[pyfunction]
fn process_document(path: String) -> PyResult<String> {
    // 测试extractous的基本功能
    Ok("Processed".to_string())
}

#[pymodule]
fn rust_test(_py: Python, m: &PyModule) -> PyResult<()> {
    m.add_function(wrap_pyfunction!(process_document, m)?)?;
    Ok(())
}

# 使用maturin构建
maturin develop
```

**验收标准**：

- [ ] Python能成功导入Rust模块
- [ ] 基本的文档处理功能可运行
- [ ] 性能对比测试：Rust vs Python处理1MB PDF

#### 2. Tauri V2 + SQLite 集成测试

```rust
// 测试sqlx编译时SQL验证
// migrations/001_init.sql
CREATE TABLE IF NOT EXISTS terms (
    id INTEGER PRIMARY KEY,
    term TEXT NOT NULL,
    definition TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

// 测试代码
use sqlx::SqlitePool;

#[derive(sqlx::FromRow)]
struct Term {
    id: i64,
    term: String,
    definition: Option<String>,
}

async fn test_db() -> Result<(), sqlx::Error> {
    let pool = SqlitePool::connect("sqlite:test.db").await?;
    
    // 编译时SQL验证
    let term = sqlx::query_as!(
        Term,
        "SELECT id, term, definition FROM terms WHERE id = ?",
        1
    )
    .fetch_optional(&pool)
    .await?;
    
    Ok(())
}
```

### 团队技能评估

- **必需技能**：Rust基础、Python异步编程、前端框架
- **建议配置**：至少需要1名熟悉Rust的开发者

------

## Phase 0: 基础架构搭建（1.5周）

### 0.1 Monorepo结构优化

```
lex-ai/
├── .github/
│   └── workflows/
│       ├── ci.yml          # 持续集成
│       └── release.yml     # 发布流程
├── backend/
│   ├── app/               # FastAPI应用
│   │   ├── api/           # API路由
│   │   ├── core/          # 核心配置
│   │   ├── models/        # 数据模型
│   │   └── services/      # 业务逻辑
│   ├── rust_core/         # Rust性能模块
│   │   ├── src/
│   │   └── Cargo.toml
│   ├── tests/             # 测试
│   ├── pyproject.toml     # Poetry配置
│   └── Dockerfile         # 容器化部署
├── client/
│   ├── src/               # 前端源码
│   ├── src-tauri/         # Tauri核心
│   │   ├── src/
│   │   │   ├── commands/  # Tauri命令
│   │   │   ├── db/        # 数据库模块
│   │   │   └── main.rs
│   │   └── Cargo.toml
│   └── package.json
├── shared/                # 共享类型定义
│   └── types.ts
└── docs/                  # 项目文档
```

### 0.2 开发环境标准化

创建统一的开发环境配置：

```yaml
# .devcontainer/devcontainer.json
{
  "name": "LexAI Dev",
  "dockerComposeFile": "docker-compose.yml",
  "service": "dev",
  "workspaceFolder": "/workspace",
  "features": {
    "ghcr.io/devcontainers/features/rust:1": {},
    "ghcr.io/devcontainers/features/python:1": {
      "version": "3.11"
    },
    "ghcr.io/devcontainers/features/node:1": {}
  }
}
```

### 0.3 错误处理框架

建立统一的错误处理机制：

```python
# backend/app/core/exceptions.py
from fastapi import HTTPException
from typing import Optional

class LexAIException(HTTPException):
    def __init__(self, 
                 status_code: int, 
                 detail: str,
                 error_code: Optional[str] = None):
        super().__init__(status_code=status_code, detail=detail)
        self.error_code = error_code

class DocumentProcessingError(LexAIException):
    def __init__(self, detail: str):
        super().__init__(
            status_code=500,
            detail=detail,
            error_code="DOC_PROCESSING_ERROR"
        )
```

------

## Phase 1: 后端核心管道（2.5周）

### 1.1 Rust文档处理核心（1周）

#### 关键实现细节

```rust
// rust_core/src/document.rs
use extractous::{Extractor, PdfExtractor};
use pyo3::prelude::*;
use pyo3::exceptions::PyIOError;

#[pyclass]
pub struct DocumentProcessor {
    extractor: Extractor,
}

#[pymethods]
impl DocumentProcessor {
    #[new]
    pub fn new() -> Self {
        Self {
            extractor: Extractor::new(),
        }
    }
    
    pub fn extract_text(&self, file_path: String) -> PyResult<Vec<String>> {
        // 返回分块的文本，而不是单一字符串
        match self.extractor.extract(&file_path) {
            Ok(chunks) => Ok(chunks),
            Err(e) => Err(PyIOError::new_err(format!("Extraction failed: {}", e)))
        }
    }
    
    pub fn extract_with_metadata(&self, file_path: String) -> PyResult<DocumentMeta> {
        // 返回包含元数据的结构
        // 页码、段落、格式信息等
    }
}

#[pyclass]
#[derive(Clone)]
pub struct DocumentMeta {
    #[pyo3(get)]
    pub chunks: Vec<TextChunk>,
    #[pyo3(get)]
    pub total_pages: Option<i32>,
    #[pyo3(get)]
    pub format: String,
}

#[pyclass]
#[derive(Clone)]
pub struct TextChunk {
    #[pyo3(get)]
    pub content: String,
    #[pyo3(get)]
    pub page: Option<i32>,
    #[pyo3(get)]
    pub paragraph: Option<i32>,
}
```

### 1.2 向量化与存储优化（1周）

#### Qdrant Schema设计

```python
# backend/app/services/vector_store.py
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
import hashlib

class VectorStore:
    def __init__(self):
        self.client = QdrantClient(host="localhost", port=6333)
        self._init_collections()
    
    def _init_collections(self):
        # 文档集合：存储文档块
        self.client.recreate_collection(
            collection_name="documents",
            vectors_config=VectorParams(
                size=768,  # sentence-transformers dimension
                distance=Distance.COSINE
            )
        )
        
        # 术语集合：存储专业术语
        self.client.recreate_collection(
            collection_name="terms",
            vectors_config=VectorParams(
                size=768,
                distance=Distance.COSINE
            )
        )
    
    async def index_document(self, doc_id: str, chunks: List[TextChunk]):
        # 批量向量化和索引
        vectors = await self._vectorize_batch([c.content for c in chunks])
        
        points = []
        for idx, (chunk, vector) in enumerate(zip(chunks, vectors)):
            point_id = hashlib.md5(f"{doc_id}_{idx}".encode()).hexdigest()
            
            points.append(PointStruct(
                id=point_id,
                vector=vector,
                payload={
                    "doc_id": doc_id,
                    "chunk_idx": idx,
                    "content": chunk.content,
                    "page": chunk.page,
                    "paragraph": chunk.paragraph
                }
            ))
        
        # 批量插入，提高性能
        self.client.upsert(
            collection_name="documents",
            points=points,
            batch_size=100
        )
```

### 1.3 性能优化策略

#### 并发处理

```python
# backend/app/services/document_service.py
import asyncio
from concurrent.futures import ThreadPoolExecutor

class DocumentService:
    def __init__(self):
        self.rust_processor = rust_core.DocumentProcessor()
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    async def process_document(self, file_path: str):
        # 在线程池中运行Rust处理，避免阻塞
        loop = asyncio.get_event_loop()
        chunks = await loop.run_in_executor(
            self.executor,
            self.rust_processor.extract_text,
            file_path
        )
        
        # 异步处理向量化
        await self.vector_store.index_document(doc_id, chunks)
```

------

## Phase 2: 客户端核心功能（3.5周）

### 2.1 Tauri命令层设计（1周）

#### 数据库访问层

```rust
// src-tauri/src/db/mod.rs
use sqlx::{SqlitePool, FromRow};
use serde::{Serialize, Deserialize};

#[derive(Debug, Serialize, Deserialize, FromRow)]
pub struct Term {
    pub id: i64,
    pub term: String,
    pub definition: Option<String>,
    pub source: Option<String>,
    pub created_at: String,
}

pub struct Database {
    pool: SqlitePool,
}

impl Database {
    pub async fn new(database_url: &str) -> Result<Self, sqlx::Error> {
        let pool = SqlitePool::connect(database_url).await?;
        sqlx::migrate!("./migrations").run(&pool).await?;
        Ok(Self { pool })
    }
    
    pub async fn add_term(&self, term: &str, definition: &str) -> Result<Term, sqlx::Error> {
        let result = sqlx::query_as!(
            Term,
            r#"
            INSERT INTO terms (term, definition) 
            VALUES (?, ?)
            RETURNING id, term, definition, source, created_at
            "#,
            term,
            definition
        )
        .fetch_one(&self.pool)
        .await?;
        
        Ok(result)
    }
}
```

#### Tauri命令实现

```rust
// src-tauri/src/commands.rs
use tauri::State;
use crate::db::{Database, Term};

#[tauri::command]
async fn add_term(
    db: State<'_, Database>,
    term: String,
    definition: String
) -> Result<Term, String> {
    db.add_term(&term, &definition)
        .await
        .map_err(|e| e.to_string())
}

#[tauri::command]
async fn search_terms(
    db: State<'_, Database>,
    query: String
) -> Result<Vec<Term>, String> {
    db.search_terms(&query)
        .await
        .map_err(|e| e.to_string())
}
```

### 2.2 前端状态管理（1周）

#### Zustand Store设计

```typescript
// src/stores/documentStore.ts
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

interface Document {
  id: string;
  name: string;
  path: string;
  status: 'uploading' | 'processing' | 'ready' | 'error';
  progress?: number;
  error?: string;
}

interface DocumentStore {
  documents: Document[];
  currentDocument: Document | null;
  
  addDocument: (doc: Document) => void;
  updateDocumentStatus: (id: string, status: Document['status']) => void;
  setCurrentDocument: (doc: Document | null) => void;
}

export const useDocumentStore = create<DocumentStore>()(
  persist(
    (set) => ({
      documents: [],
      currentDocument: null,
      
      addDocument: (doc) => 
        set((state) => ({
          documents: [...state.documents, doc]
        })),
        
      updateDocumentStatus: (id, status) =>
        set((state) => ({
          documents: state.documents.map(d => 
            d.id === id ? { ...d, status } : d
          )
        })),
        
      setCurrentDocument: (doc) => 
        set({ currentDocument: doc })
    }),
    {
      name: 'document-storage',
      partialize: (state) => ({ documents: state.documents })
    }
  )
);
```

### 2.3 AI集成层（1.5周）

#### LLM调度器

```typescript
// src/lib/llm/dispatcher.ts
import { invoke } from '@tauri-apps/api/tauri';

interface LLMConfig {
  provider: 'openai' | 'anthropic' | 'custom';
  model: string;
  apiKey?: string;
  baseUrl?: string;
}

interface LLMRequest {
  function: 'term_extraction' | 'explanation' | 'onboarding';
  prompt: string;
  maxTokens?: number;
  temperature?: number;
}

class LLMDispatcher {
  private configs: Map<string, LLMConfig> = new Map();
  
  async loadConfigs() {
    // 从Tauri secure storage加载配置
    const configs = await invoke<Record<string, LLMConfig>>('get_llm_configs');
    Object.entries(configs).forEach(([fn, config]) => {
      this.configs.set(fn, config);
    });
  }
  
  async call(request: LLMRequest): Promise<any> {
    const config = this.configs.get(request.function);
    if (!config) {
      throw new Error(`No configuration for function: ${request.function}`);
    }
    
    // 获取API密钥
    const apiKey = config.apiKey || 
      await invoke<string>('get_api_key', { provider: config.provider });
    
    // 构建请求
    const response = await this.sendRequest({
      ...config,
      apiKey,
      prompt: request.prompt,
      maxTokens: request.maxTokens || 1000,
      temperature: request.temperature || 0.7
    });
    
    return this.parseResponse(response, request.function);
  }
  
  private async sendRequest(params: any): Promise<any> {
    // 实现不同provider的API调用
    switch (params.provider) {
      case 'openai':
        return this.callOpenAI(params);
      case 'anthropic':
        return this.callAnthropic(params);
      default:
        return this.callCustom(params);
    }
  }
  
  private parseResponse(response: any, functionType: string): any {
    // 根据功能类型解析响应
    switch (functionType) {
      case 'term_extraction':
        // 期望JSON数组格式
        return this.parseTermsJSON(response);
      case 'explanation':
        // 期望纯文本
        return response.content || response.text;
      default:
        return response;
    }
  }
}

export const llmDispatcher = new LLMDispatcher();
```

------

## Phase 3: 高级功能与优化（2.5周）

### 3.1 对话式引导实现（1周）

#### 智能Prompt构建

```typescript
// src/components/Onboarding/OnboardingWizard.tsx
interface OnboardingState {
  domain: string;
  level: 'beginner' | 'intermediate' | 'advanced';
  goals: string[];
  customRequirements?: string;
}

class OnboardingPromptBuilder {
  build(state: OnboardingState): string {
    const levelDescriptions = {
      beginner: "just starting to learn",
      intermediate: "can read basic papers",
      advanced: "comfortable with technical literature"
    };
    
    return `
You are an expert in ${state.domain}. Generate a comprehensive termbase for someone who is ${levelDescriptions[state.level]} in this field.

Goals: ${state.goals.join(', ')}
${state.customRequirements ? `Additional requirements: ${state.customRequirements}` : ''}

Generate exactly 200 essential terms with concise, professional definitions.
Format as JSON array: [{"term": "...", "definition": "...", "difficulty": 1-5}]

Focus on:
1. Core fundamental concepts (40%)
2. Frequently used technical terms (30%)
3. Important acronyms and abbreviations (20%)
4. Cutting-edge terminology (10%)

Ensure definitions are:
- Concise (one sentence when possible)
- Technically accurate
- Appropriate for the user's level
`;
  }
}
```

### 3.2 配置中心UI（0.5周）

#### 安全凭证管理

```rust
// src-tauri/src/security.rs
use keyring::Entry;
use serde_json::json;

pub struct SecureStorage {
    service: String,
}

impl SecureStorage {
    pub fn new() -> Self {
        Self {
            service: "lexai".to_string(),
        }
    }
    
    pub fn save_api_key(&self, provider: &str, key: &str) -> Result<(), String> {
        let entry = Entry::new(&self.service, provider)
            .map_err(|e| e.to_string())?;
            
        entry.set_password(key)
            .map_err(|e| e.to_string())
    }
    
    pub fn get_api_key(&self, provider: &str) -> Result<String, String> {
        let entry = Entry::new(&self.service, provider)
            .map_err(|e| e.to_string())?;
            
        entry.get_password()
            .map_err(|e| e.to_string())
    }
    
    pub fn delete_api_key(&self, provider: &str) -> Result<(), String> {
        let entry = Entry::new(&self.service, provider)
            .map_err(|e| e.to_string())?;
            
        entry.delete_password()
            .map_err(|e| e.to_string())
    }
}
```

### 3.3 性能监控与优化（1周）

#### 性能指标收集

```typescript
// src/lib/monitoring.ts
class PerformanceMonitor {
  private metrics: Map<string, number[]> = new Map();
  
  async measure<T>(name: string, fn: () => Promise<T>): Promise<T> {
    const start = performance.now();
    
    try {
      const result = await fn();
      const duration = performance.now() - start;
      
      this.recordMetric(name, duration);
      
      // 发送到后端进行聚合分析
      if (duration > 1000) {
        await this.reportSlowOperation(name, duration);
      }
      
      return result;
    } catch (error) {
      this.recordError(name, error);
      throw error;
    }
  }
  
  private recordMetric(name: string, duration: number) {
    const metrics = this.metrics.get(name) || [];
    metrics.push(duration);
    
    // 保持最近100个样本
    if (metrics.length > 100) {
      metrics.shift();
    }
    
    this.metrics.set(name, metrics);
  }
  
  getStats(name: string) {
    const metrics = this.metrics.get(name) || [];
    if (metrics.length === 0) return null;
    
    const sorted = [...metrics].sort((a, b) => a - b);
    return {
      avg: metrics.reduce((a, b) => a + b, 0) / metrics.length,
      p50: sorted[Math.floor(sorted.length * 0.5)],
      p95: sorted[Math.floor(sorted.length * 0.95)],
      p99: sorted[Math.floor(sorted.length * 0.99)]
    };
  }
}
```

------

## Phase 4: 测试、部署与发布（2周）

### 4.1 测试策略（1周）

#### 单元测试

```python
# backend/tests/test_document_processor.py
import pytest
from pathlib import Path
import rust_core

@pytest.fixture
def sample_pdf():
    return Path(__file__).parent / "fixtures" / "sample.pdf"

@pytest.fixture
def processor():
    return rust_core.DocumentProcessor()

def test_extract_text(processor, sample_pdf):
    chunks = processor.extract_text(str(sample_pdf))
    assert len(chunks) > 0
    assert all(isinstance(chunk, str) for chunk in chunks)

def test_extract_with_metadata(processor, sample_pdf):
    meta = processor.extract_with_metadata(str(sample_pdf))
    assert meta.format == "pdf"
    assert meta.total_pages > 0
    assert len(meta.chunks) > 0

@pytest.mark.benchmark
def test_performance(benchmark, processor, sample_pdf):
    # 性能基准测试
    result = benchmark(processor.extract_text, str(sample_pdf))
    assert result is not None
```

#### 集成测试

```typescript
// client/tests/integration.test.ts
import { test, expect } from '@playwright/test';

test.describe('Document Processing Flow', () => {
  test('should upload and process document', async ({ page }) => {
    await page.goto('http://localhost:1420');
    
    // 上传文档
    const fileInput = page.locator('input[type="file"]');
    await fileInput.setInputFiles('./fixtures/test.pdf');
    
    // 等待处理完成
    await expect(page.locator('.document-status')).toHaveText('ready', {
      timeout: 30000
    });
    
    // 提取术语
    await page.click('button:text("Extract Terms")');
    
    // 验证术语列表
    await expect(page.locator('.term-item')).toHaveCount(20, {
      timeout: 10000
    });
  });
});
```

### 4.2 CI/CD Pipeline（0.5周）

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test-backend:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Setup Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      
      - name: Install Poetry
        run: pip install poetry
      
      - name: Install dependencies
        working-directory: ./backend
        run: |
          poetry install
          maturin develop --release
      
      - name: Run tests
        working-directory: ./backend
        run: poetry run pytest --cov=app --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3

  test-client:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node
        uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Setup Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      
      - name: Install dependencies
        working-directory: ./client
        run: |
          npm ci
          npm run tauri build -- --debug
      
      - name: Run tests
        working-directory: ./client
        run: npm test

  release:
    needs: [test-backend, test-client]
    if: startsWith(github.ref, 'refs/tags/v')
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        include:
          - os: ubuntu-latest
            target: x86_64-unknown-linux-gnu
          - os: windows-latest
            target: x86_64-pc-windows-msvc
          - os: macos-latest
            target: x86_64-apple-darwin
          - os: macos-latest
            target: aarch64-apple-darwin
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup toolchain
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          target: ${{ matrix.target }}
      
      - name: Build and upload
        uses: tauri-apps/tauri-action@v0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tagName: ${{ github.ref_name }}
          releaseName: 'LexAI ${{ github.ref_name }}'
          releaseBody: 'See CHANGELOG.md for details'
          releaseDraft: false
          prerelease: false
```

### 4.3 部署文档（0.5周）

```markdown
# 部署指南

## 后端部署（Docker）

### 1. 构建镜像
\`\`\`bash
cd backend
docker build -t lexai-backend:latest .
\`\`\`

### 2. 运行容器
\`\`\`bash
docker run -d \
  --name lexai-backend \
  -p 8000:8000 \
  -v qdrant_data:/qdrant/storage \
  lexai-backend:latest
\`\`\`

## 客户端分发

### Windows
- 下载 `LexAI_x.x.x_x64.msi`
- 双击安装
- 需要 Windows 10 1809+ 或 Windows 11

### macOS
- 下载 `LexAI_x.x.x_x64.dmg` (Intel) 或 `LexAI_x.x.x_aarch64.dmg` (Apple Silicon)
- 打开DMG，拖动到Applications
- 首次运行需要右键选择"打开"

### Linux
- Ubuntu/Debian: `sudo dpkg -i lexai_x.x.x_amd64.deb`
- 其他发行版: 使用 `.AppImage` 版本
```

------

## 风险缓解策略

### 1. 技术风险

- **PyO3集成问题**: 准备纯Python降级方案
- **Tauri V2稳定性**: 保持Electron分支作为备选
- **Qdrant性能**: 准备ChromaDB作为轻量替代

### 2. 进度风险

- **核心功能优先**: 确保Phase 1-2完成即可发布MVP
- **增量发布**: 每2周发布一个可用版本
- **功能降级**: 复杂功能可以简化实现

### 3. 质量保障

- **代码审查**: 所有PR必须经过review
- **自动化测试**: 覆盖率保持80%以上
- **性能监控**: 建立性能基准线

------

## 成功指标

### 技术指标

- 文档处理速度: < 2秒/MB
- 术语提取准确率: > 85%
- 应用启动时间: < 3秒
- 内存占用: < 200MB

### 用户指标

- 首次使用到价值实现: < 5分钟
- 日活跃用户留存: > 40%
- 用户满意度: > 4.0/5.0

### 项目指标

- 代码测试覆盖率: > 80%
- 文档完整性: API文档100%覆盖
- 发布周期: 2周一个迭代
- Bug修复时间: P0 < 24小时, P1 < 3天

------

## 关键决策点与里程碑

### Week 2 决策点

- [ ] PyO3集成是否成功？
- [ ] 如果失败：切换到纯Python方案还是继续优化？
- [ ] 性能测试结果是否达标？

### Week 4 里程碑 (MVP)

- [ ] 完整的文档上传->处理->检索流程
- [ ] 基本的术语提取功能
- [ ] 可发布的最小可行产品

### Week 6 决策点

- [ ] 用户配置功能的复杂度是否合理？
- [ ] 是否需要简化配置流程？
- [ ] 移动端开发是否纳入下一阶段？

### Week 8 里程碑 (V1.0)

- [ ] 所有核心功能完成
- [ ] 通过所有测试
- [ ] 文档完整
- [ ] 可公开发布的产品版本

------

## 长期演进路线

### V1.x (3个月)

- 稳定性改进
- 性能优化
- 更多文档格式支持 (EPUB, Markdown, LaTeX)
- 云同步功能

### V2.0 (6个月)

- 移动端应用 (iOS/Android)
- 团队协作功能
- 自定义模型训练
- 插件系统

### V3.0 (12个月)

- 完整的知识图谱
- 智能学习路径推荐
- 多语言支持
- 企业版本